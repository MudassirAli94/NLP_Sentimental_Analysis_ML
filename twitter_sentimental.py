# -*- coding: utf-8 -*-
"""Twitter Sentimental.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MBczW07A-lQqaO5UASWVqHifdB0lxMzg

# Twitter Sentimental Analysis
"""

import numpy as np
import pandas as pd
from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('drive/My Drive/Colab Notebooks/twitter sentiment/Tweets.csv')
df.head()

# For sentimental analysis I just want the actual tweet and the label for it

tweet = df[['airline_sentiment', 'text']].copy()
tweet.head()

tweet.isnull().sum()

blanks = []

# (index,label, review text)
for i,lb,rv in tweet.itertuples():
  if rv.isspace():
    blanks.append(i)

blanks

# There are no missing values and there are no blanks within the text so we can proceed with the sentiment analysis

import nltk
nltk.download('vader_lexicon')
from nltk.sentiment.vader import SentimentIntensityAnalyzer
sid = SentimentIntensityAnalyzer()

tweet['score'] = tweet['text'].apply(lambda review:sid.polarity_scores(review))
tweet['compound'] = tweet['score'].apply(lambda d:d['compound'])
tweet['comp_score'] = tweet['compound'].apply(lambda score: 'positive' if score > 0 else ('neutral' if score == 0.00 else 'negative'))

tweet.head()

# If the compound score is 0 it is neutral, >0 positive, <0 negative

# Now that we caluclating the sentimental analysis via NLTK let's see how it
# it fairs via confusion matrix and classification reports

from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

print(accuracy_score(tweet['airline_sentiment'] ,tweet['comp_score']))
print(classification_report(tweet['airline_sentiment'] , tweet['comp_score']))

# We can see that our analysis is only 50% accurate however this is just
# a simple method of using nltk, let's try using machine learning

tweet.comp_score.value_counts()

#there is an imbalancement so we will have to balance the dataset and we want to
# use our generated comp_score because in the real world there is no label if
# the sentiment is positive, neutral or negative

from sklearn.utils import resample

# Separate majority and minority classes
df_majority = tweet[tweet.comp_score =='positive']
df_minority = tweet[tweet.comp_score =='negative']
df_minority1 = tweet[tweet.comp_score == 'neutral']
 
# Upsample minority class
df_minority_upsampled = resample(df_minority, 
                                 replace=True,     # sample with replacement
                                 n_samples=6222,    # to match majority class
                                 random_state=123) # reproducible results

df_minority1_upsampled = resample(df_minority1, 
                                 replace=True,    
                                 n_samples=6222,    
                                 random_state=123)
 
# Combine majority class with upsampled minority class
new_tweet = pd.concat([df_majority, df_minority_upsampled , df_minority1_upsampled])
 
# Display new class counts
new_tweet.comp_score.value_counts()

from sklearn.model_selection import train_test_split

X = new_tweet['text' ]
y = new_tweet['comp_score']

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33,
                                                   random_state = 42)

from sklearn.feature_extraction.text import TfidfVectorizer

# TfidfVectorizer combines the steps of countvectorization and tfidftransformer
# Basically it learns the vocabulary, counts the number of words then transform
# X_train to a numerical vector while also gives important words more weight

from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC

text_clf = Pipeline([('tfidf', TfidfVectorizer(max_df= 0.95, min_df= 2, 
                                               stop_words= 'english')), 
                     ('clf' , LinearSVC())])
text_clf.fit(X_train,y_train)
predictions = text_clf.predict(X_test)

print(classification_report(y_test, predictions))

print(accuracy_score(y_test ,predictions))

from sklearn.linear_model import LogisticRegression

text_clf1 = Pipeline([('tfidf', TfidfVectorizer(max_df= 0.95, min_df= 2, 
                                               stop_words= 'english')), 
                     ('Log' , LogisticRegression())])
text_clf1.fit(X_train,y_train)
predictions1 = text_clf1.predict(X_test)
print(classification_report(y_test, predictions1))
print(accuracy_score(y_test ,predictions1))

from sklearn.tree import DecisionTreeClassifier

text_clf2 = Pipeline([('tfidf', TfidfVectorizer(max_df= 0.95, min_df= 2, 
                                               stop_words= 'english')), 
                     ('DT' , DecisionTreeClassifier())])
text_clf2.fit(X_train,y_train)
predictions2 = text_clf2.predict(X_test)
print(classification_report(y_test, predictions2))
print(accuracy_score(y_test ,predictions2))

from sklearn.ensemble import RandomForestClassifier

text_clf3 = Pipeline([('tfidf', TfidfVectorizer(max_df= 0.95, min_df= 2, 
                                               stop_words= 'english')), 
                     ('RF' , RandomForestClassifier(n_estimators=100))])
text_clf3.fit(X_train,y_train)
predictions3 = text_clf3.predict(X_test)
print(classification_report(y_test, predictions3))
print(accuracy_score(y_test ,predictions3))

# As we can see the highest accuracy was with LinearSVC at around 84%
# We can test out our prediction

for i in range(0,20):  
  print("Label of tweet",[tweet.iloc[:,0][i]])
  print("Actual tweet",[tweet.iloc[:,1][i]])
  print("Computed Score of tweet",[tweet.iloc[:,3][i]])
  print("Predicted label",text_clf.predict([tweet.iloc[:,1][i]]))
  print('\n')

# For the most part our predictive label matches with the actual label
# Some of the improvements would be replacing emojis with words
# Taking out hashtags